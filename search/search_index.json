{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#github-workflows","title":"GitHub Workflows","text":"<p>This repository contains a collection of GitHub workflows that are reusable across projects.</p> <p>The main goal is to have a single source of truth for all workflows, so that they can be easily updated and reused.</p> <p>Features include, but are not limited to:</p> <ul> <li>terraform management</li> <li>aws authentication</li> <li>docker image management</li> <li>lambda builds</li> <li>Copy of AWS secrets across AWS accounts</li> </ul> <p>The state of these workflows are considered to be in alpha, and are subject to change to suit the needs of projects managed by DAI.</p>"},{"location":"#usage","title":"Usage","text":"<p>Create a <code>.github/workflows</code> directory in your repository and create workflows that reference the workflows in this repository.</p> <pre><code>name: My Workflow\non: push\njobs:\n  my-job:\n    uses: &lt;org&gt;/&lt;repo&gt;/.github/workflows/&lt;workflow-name&gt;.yaml@&lt;ref&gt;\n    with:\n      my-input: my-value\n</code></pre> <p>For more usage examples please look for the <code>_test-*</code> workflow definition in the <code>.github/workflows/</code> folder.</p>"},{"location":"#quick-start-guide-for-reusable-workflows","title":"Quick Start Guide for Reusable Workflows","text":"<p>To get started with using reusable workflows in your repository, follow these steps:</p> <ol> <li> <p>Create a <code>.github/workflows</code> directory in your repository if it doesn't already exist.</p> </li> <li> <p>Copy an example workflow file from the reusable workflows repository into your <code>.github/workflows</code> directory. You can find the workflow example files in the <code>.github/workflows/samples</code> folder of this repository.</p> </li> <li> <p>Open the workflow file you just copied and customize it according to your needs. Each workflow file contains a set of jobs that define the tasks to be executed.</p> </li> <li> <p>Make sure to set the required inputs for the workflow. These inputs are defined in the workflow file and can be customized to match your specific requirements. For example, you might need to provide values for environment variables, AWS credentials, or Docker image details.</p> </li> <li> <p>Save the modified workflow file.</p> </li> <li> <p>Commit and push the changes to your repository.</p> </li> <li> <p>The workflow will now be triggered based on the specified events. For example, if you have configured the workflow to run on every push event, it will automatically start whenever you push changes to your repository.</p> </li> </ol> <p>That's it! You have successfully set up and customized a reusable workflow in your repository. Now you can benefit from the predefined tasks and automation provided by the workflow to streamline your development process.</p> <p>For the list and documentation of the maintained workflows, please have a look below!</p>"},{"location":"#maintained-workflows","title":"Maintained workflows","text":"<p>Each workflow has its own dedicated documentation. For a detailed understanding, you should go through the code and understand each step and how they interact with each other.</p> <p>Most of the workflows do some \"black magic\", by getting values by default from your Github Environments, if set as <code>environment</code> input.</p>"},{"location":"#terraform-deployment","title":"Terraform Deployment","text":"<p>This workflow is responsible for deploying infrastructure using Terraform through dflook. For more information see Terraform Deployment Documentation.</p>"},{"location":"#feature-branches-deployment","title":"Feature branches deployment","text":"<p>A common use case is to have feature branches deployment to test changes before they reach the <code>main</code> branch. To achieve that you can use the <code>tf-feature</code> workflow. Remember to use the <code>tf-cleanup</code> workflow too once you're done with it so that Terraform can cleanup the dangling resources.</p>"},{"location":"#docker-build-and-push-to-ecr","title":"Docker Build and Push to ECR","text":"<p>The <code>docker-build-push-ecr.yaml</code> builds a Docker image and pushes it to the Elastic Container Registry (ECR). It's triggered on a workflow_call event and accepts several inputs. For more information see Docker build and push documentation.</p>"},{"location":"#release","title":"Release","text":"<p>This workflow handles the release process, including versioning and tagging. For more information see Release Documentation.</p>"},{"location":"#lambda-build-node","title":"Lambda Build Node","text":"<p>This workflow is responsible for building the Lambda function using Node.js. For more information see Lambda Build Node Documentation.</p>"},{"location":"#development-guidelines","title":"Development Guidelines","text":"<p>When modifying any of these workflows, ensure that you adhere to the following guidelines:</p> <ul> <li> <p>Inputs : All inputs should be clearly defined at the top of the workflow. Each input should have a description, type, and whether it is required or not.</p> </li> <li> <p>Jobs : Each job should have a clear purpose and should be named accordingly.</p> </li> <li> <p>Steps : Each step within a job should be atomic, meaning it should do one thing and do it well.</p> </li> <li> <p>Errors : Ensure that any potential errors are handled gracefully and provide clear error messages.</p> </li> </ul>"},{"location":"#documentation-related-to-github-actions","title":"Documentation related to GitHub Actions","text":"<p>Documentation: GitHub Actions - Documentation GitHub</p>"},{"location":"#releases","title":"Releases","text":"<p>Release pipeline is triggered on each PR merged to main, which creates a new release incrementing automatically minor version.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Before creating a new shared workflow, check if something similar already exists. If it does, consider updating the existing workflow instead of creating a new one.</p> <p>If you want to create a new workflow, please follow these steps:</p> <ul> <li>Name the workflow files similar to the following <code>&lt;tool/service&gt;-&lt;simple description&gt;.yaml</code>.</li> <li>The less inputs, the better.</li> <li>Files uses dash-case and variables use snake_case.</li> </ul>"},{"location":"#testing","title":"Testing","text":"<p>Each workflow should have a <code>test</code> job that runs the workflow with different inputs. This job should be triggered on when changes are detected and push to main.</p> <p>Test workflows are prefixed with <code>_test-</code> and contain the workflow file name. One test workflow per workflow file which can contain multiple jobs.</p>"},{"location":"faq/","title":"FAQ","text":"<p>tba</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This getting started guide will help you deploy your first EKS cluster.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have installed the following tools locally:</p> <ul> <li>awscli</li> <li>kubectl</li> <li>terraform</li> </ul>"},{"location":"getting-started/#deploy","title":"Deploy","text":"<ol> <li> <p>For consuming EKS Blueprints, please see the Consumption section. For exploring and trying out the patterns provided, please clone the project locally to quickly get up and running with a pattern. After cloning the project locally, <code>cd</code> into the pattern directory of your choice.</p> </li> <li> <p>To provision the pattern, the typical steps of execution are as follows:</p> <pre><code>terraform init\nterraform apply -auto-approve\n</code></pre> <p>For patterns that deviate from this general flow, see the pattern's respective <code>README.md</code> for more details.</p> <p>Terraform targeted apply</p> <p>Please see the Terraform Caveats section for details on the use of targeted Terraform apply's</p> </li> <li> <p>Once all of the resources have successfully been provisioned, the following command can be used to update the <code>kubeconfig</code> on your local machine and allow you to interact with your EKS Cluster using <code>kubectl</code>.</p> <pre><code>aws eks --region &lt;REGION&gt; update-kubeconfig --name &lt;CLUSTER_NAME&gt; --alias &lt;CLUSTER_NAME&gt;\n</code></pre> <p>Pattern Terraform outputs</p> <p>Most examples will output the <code>aws eks update-kubeconfig ...</code> command as part of the Terraform apply output to simplify this process for users</p> <p>Private clusters</p> <p>Clusters that do not enable the clusters public endpoint will require users to access the cluster from within the VPC. For these patterns, a sample EC2 or other means are provided to demonstrate how to access those clusters privately</p> <p>and without exposing the public endpoint. Please see the respective pattern's <code>README.md</code> for more details.</p> </li> <li> <p>Once you have updated your <code>kubeconfig</code>, you can verify that you are able to interact with your cluster by running the following command:</p> <pre><code>kubectl get nodes\n</code></pre> <p>This should return a list of the node(s) running in the cluster created. If any errors are encountered, please re-trace the steps above and consult the pattern's <code>README.md</code> for more details on any additional/specific steps that may be required.</p> </li> </ol>"},{"location":"getting-started/#destroy","title":"Destroy","text":"<p>To teardown and remove the resources created in the pattern, the typical steps of execution are as follows:</p> <pre><code>terraform destroy -auto-approve\n</code></pre> <p>Resources created outside of Terraform</p> <p>Depending on the pattern, some resources may have been created that Terraform is not aware of that will cause issues when attempting to clean up the pattern. For example, Karpenter is responsible for creating additional EC2 instances to satisfy the pod scheduling requirements. These instances will not be cleaned up by Terraform and will need to be de-provisioned BEFORE attempting to <code>terraform destroy</code>. This is why it is important that the addons, or any resources provisioned onto the cluster are cleaned up first. Please see the respective pattern's <code>README.md</code> for more details.</p>"},{"location":"examples/terraform/","title":"Terraform","text":"<p>Application Deployment Workflow</p> <pre><code>name: Application\non:\n  push:\n    branches:\n      - main\n    paths-ignore:\n      - \"README.md\"\n      - \"renovate.json\"\n  pull_request:\n    branches:\n      - main\n    paths-ignore:\n      - \"README.md\"\n      - \"renovate.json\"\n  workflow_dispatch:\n\npermissions:\n  id-token: write\n  contents: read\n  pull-requests: write\n\njobs:\n  docker_build_artifact:\n    if: github.event_name == 'pull_request'\n    uses: tx-pts-dai/github-workflows/.github/workflows/docker-build.yaml@ece8993c7f7e419bc658a7036cd281f0ad0968b6 # v1.0.1\n\n  docker_push_ecr:\n    if: github.event_name == 'push'\n    strategy:\n      fail-fast: false\n      matrix:\n        stack: [app]\n        environment: [dev, int, prod]\n    uses: tx-pts-dai/github-workflows/.github/workflows/docker-push-ecr.yaml@ece8993c7f7e419bc658a7036cd281f0ad0968b6 # v1.0.1\n    with:\n      environment: ${{ matrix.stack }}-${{ matrix.environment }}\n\n  plan:\n    if: github.event_name == 'pull_request'\n    strategy:\n      fail-fast: false\n      matrix:\n        stack: [app]\n        environment: [dev, int, prod]\n    uses: tx-pts-dai/github-workflows/.github/workflows/tf-plan.yaml@ece8993c7f7e419bc658a7036cd281f0ad0968b6 # v1.0.1\n    with:\n      environment: ${{ matrix.stack }}-${{ matrix.environment }}\n\n  apply:\n    if: github.ref_name == github.event.repository.default_branch &amp;&amp; (github.event_name == 'push' || github.event_name == 'workflow_dispatch')\n    strategy:\n      fail-fast: false\n      matrix:\n        stack: [app]\n        environment: [dev, int, prod]\n    uses: tx-pts-dai/github-workflows/.github/workflows/tf-apply.yaml@ece8993c7f7e419bc658a7036cd281f0ad0968b6 # v1.0.1\n    with:\n      environment: ${{ matrix.stack }}-${{ matrix.environment }}\n</code></pre>"},{"location":"workflows/aws-secrets-copy/","title":"Quick start guide","text":"<p>aws-secrets-copy.yaml is a GitHub Action Job designed to copy an AWS secret between two AWS accounts.</p>"},{"location":"workflows/aws-secrets-copy/#inputs","title":"Inputs","text":"Input Description Required source_aws_region AWS region Yes source_aws_oidc_role_arn AWS OIDC IAM role to assume Yes source_secret_name AWS secret name to copy from Yes destination_aws_region AWS region Yes destination_aws_oidc_role_arn AWS OIDC IAM role to assume No destination_secret_name AWS secret name to copy to (default to source secret name) No secret_description The description to attach to the AWS secret (default to source description) No aws_tags Tags to put on the created secret in the form '[{\"Key\":\"key1\", \"Value\":\"value1\"},{\"Key\":\"key2\", \"Value\":\"value2\"}]' No"},{"location":"workflows/aws-secrets-copy/#examples","title":"Examples","text":"<pre><code>on: [push, pull_request]\njobs:\n  copy_secret:\n    uses: ./.github/workflows/aws-secrets-copy.yaml\n    with:\n      source_aws_region: 'us-west-2'\n      source_aws_oidc_role_arn: 'arn:aws:iam::123456789012:role/my-aws-role'\n      source_secret_name: ' my-aws-secret'\n      destination_aws_region: 'us-west-1'\n      destination_aws_oidc_role_arn: 'arn:aws:iam::012345678901:role/my-aws-role'\n</code></pre>"},{"location":"workflows/aws-secrets-copy/#faqs","title":"FAQs","text":"<p>Q: What happen if the destination secret already exists ?</p> <p>A: The destination AWS secret value will be updated to the value of the source secret</p>"},{"location":"workflows/aws-secrets-copy/#workflow","title":"Workflow","text":"<p>There is a validation workflow triggered when a pull request from a feature branch to <code>main</code> is created. The workflow will create some temporary AWS secrets to validate that different use cases of the workflow will work:</p> <ul> <li>Copy of a secret to non existing secret</li> <li>Copy of a secret to an existing secret</li> <li>Copy of a secret with different input parameters</li> </ul> <p>At the end, all secrets are deleted</p>"},{"location":"workflows/docker-build-push/","title":"Quick start guide","text":"<p>The <code>docker-build-push-ecr.yaml</code> is a GitHub Action workflow designed to automate the process of building a Docker image and pushing it to Amazon ECR. It's triggered on a <code>workflow_call</code> event and accepts several inputs.</p>"},{"location":"workflows/docker-build-push/#inputs","title":"Inputs","text":"Input Description Required Default environment The environment to run the build in Yes aws_account_id The AWS Account ID Yes aws_region The AWS Region Yes aws_role_name The AWS Role Name Yes aws_oidc_role_arn The AWS OIDC IAM role to assume Yes image_name The name of the Docker image to build No The repository name image_tag The tag of the Docker image to build Yes docker_context The path to the build context No . dockerfile_path The path to the Dockerfile No {docker_context}/Dockerfile docker_push Whether to push the image to ECR No true artifact_name Artifact name to be downloaded No artifact_path Artifact target path No"},{"location":"workflows/docker-build-push/#examples","title":"Examples","text":"<pre><code>on: [push, pull_request]\njobs:\n  docker_build_push_ecr:\n    uses: ./.github/workflows/docker-build-push-ecr.yaml\n    with:\n      environment: 'production'\n      aws_region: 'us-west-2'\n      aws_oidc_role_arn: 'arn:aws:iam::123456789012:role/my-aws-role'\n      image_name: 'my-docker-image'\n      image_tag: 'latest'\n      docker_context: '.'\n      dockerfile_path: 'Dockerfile'\n      docker_push: 'true'\n</code></pre>"},{"location":"workflows/docker-build-push/#faqs","title":"FAQs","text":"<p>Q: How do I specify the AWS credentials?</p> <p>A: The AWS credentials are specified using the aws_account_id, aws_region, aws_role_name, and aws_oidc_role_arn inputs.</p> <p>Q: How do I specify the Docker image name and tag?</p> <p>A: The Docker image name and tag are specified using the image_name and image_tag inputs. By default, the image name is the repository name.</p> <p>Q: How do I specify the build context and Dockerfile path?</p> <p>A: The build context and Dockerfile path are specified using the docker_context and dockerfile_path inputs. By default, the build context is . and the Dockerfile path is {docker_context}/Dockerfile.</p> <p>Q: How do I control whether the image is pushed to ECR?</p> <p>A: Whether the image is pushed to ECR is controlled using the docker_push input. By default, it is set to true.</p> <p>Q: Can I only build or only push ?</p> <p>A: Yes you can call separately the workflows docker-build.yaml and docker-push-ecr.yaml. Please refer to each individual workflow for informations about inputs.</p> <p>Q: Can I pass files and folders from other jobs?</p> <p>A: Yes, you can upload them as artifacts and have the docker-build-push-ecr.yaml to download them via <code>artifact_path</code> and <code>artifact_name</code>. Example <code>DND-IT/disco</code> PR</p>"},{"location":"workflows/github-release/","title":"Quick Start Guide","text":"<p>This GitHub Action is designed to automate the process of creating a new release on push to the main branch. It's triggered on a pull_request closed event to the main branch and does not require any inputs.</p> <p>However, it requires specific naming convention for the commit message in order to release the right version.</p> <p>The release automatically increases the patch, minor or major version, but also tags the MAJOR and MAJOR.MINOR versions to point to the latest commit.</p> <p>The workflow pays attention to the title of the latest commit and check what it starts with. Which means that when squashing and merging your PR, you need to add the proper key words.</p> <p>The options are: 1. \"fix: Some comment\" -&gt; will increment the patch version x.x.PATCH+1 2. \"feat: Some comment\" -&gt; will increment the minor version x.MINOR+1.0 3. \"feat!: Some comment\" -&gt; will increment the major version MAJOR+1.0.0</p>"},{"location":"workflows/github-release/#inputs","title":"Inputs","text":"<p>No inputs.</p>"},{"location":"workflows/github-release/#examples","title":"Examples","text":"<ul> <li> <p>we currently are at version v1.1.1. . Squashing/merging a PR with a \"fix:\" prefix will increase the patch version (-&gt; v1.1.2), and also will renew tagging so that workflows already calling @v1 or @v1.1 would target the new release v1.1.2.</p> </li> <li> <p>we currently are at version v1.1.9. Squashing/merging a PR with a \"feat:\" prefix will increase the minor version (-&gt; v1.2.0), and also will renew tagging so that workflows already calling @v1 or @v1.2 would target the new release v1.2.0.</p> </li> </ul>"},{"location":"workflows/github-release/#faqs","title":"FAQs","text":"<p>Q: How is the version number determined?</p> <p>A: The version number is determined by fetching all tags, sorting them, and retrieving the latest version. If no tags are found, it defaults to v0.0.1.</p> <p>Q: How are the release notes generated?</p> <p>A: The release notes are automatically generated by the <code>softprops/action-gh-release@v1</code> action.</p>"},{"location":"workflows/lambda-build-node/","title":"Quick start guide","text":"<p>The <code>lambda-build-node.yaml</code> is a GitHub Action workflow designed to automate the process of building a Node.js AWS Lambda function. It's triggered on a <code>workflow_call</code> event and accepts several inputs.</p>"},{"location":"workflows/lambda-build-node/#inputs","title":"Inputs","text":"Input Description Required Default <code>node_version</code> The Node.js version to use No 20 <code>source_dir</code> The directory where the Lambda source code is located No src <code>build_dir</code> The directory where the Lambda build artifacts are located No dist <code>artifact_retention_days</code> Number of days to retain the artifact No 5"},{"location":"workflows/lambda-build-node/#examples","title":"Examples","text":"<pre><code>on: [push, pull_request]\njobs:\n  build:\n    uses: ./.github/workflows/lambda-build-node.yaml\n    with:\n      node_version: \"20\"\n      source_dir: \"src\"\n      build_dir: \"dist\"\n      artifact_retention_days: 5\n</code></pre>"},{"location":"workflows/lambda-build-node/#faqs","title":"FAQs","text":"<p>Q: How do I specify the Node.js version?</p> <p>A: The Node.js version is specified using the node_version input. By default, it uses version 20.</p> <p>Q: How do I specify the source directory?</p> <p>A: The source directory is specified using the source_dir input. By default, it is set to src.</p> <p>Q: How do I specify the build directory?</p> <p>A: The build directory is specified using the build_dir input. By default, it is set to dist.</p> <p>Q: How do I specify the artifact retention days?</p> <p>A: The number of days to retain the artifact is specified using the artifact_retention_days input. By default, it is set to 5 days.</p>"},{"location":"workflows/terraform/","title":"Quick start guide","text":"<p>dflook actions are an externally maintained set of actions that are used in the workflows. The decision to use dflook actions was made to reduce the maintenance burden of the workflows and reuse actions that are well tested and reliable.</p>"},{"location":"workflows/terraform/#inputs-for-dflook-workflows","title":"Inputs for dflook workflows","text":"<p>Each reusable workflow should contain related tasks to reduce any duplication of tasks across workflows. eg. <code>plan</code> runs validate and format before the plan to catch any issues early and not have to rely on creating extra workflows to run these tasks. For an updated list of inputs, see directly the dflook repository.</p> <p>Assumptions when using dflook actions:</p> <ul> <li>the environment input is set for all actions.</li> <li>inputs are either passed directly to the action or are set as environment variables.</li> </ul>"},{"location":"workflows/terraform/#examples","title":"Examples","text":"<pre><code>on:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - '.github/workflows/_test-tf.yaml'\n      - '.github/workflows/tf-*.yaml'\n      - 'tests/terraform/**'\n  push:\n    branches:\n      - main\n\njobs:\n  test_tf_plan:\n    uses: ./.github/workflows/tf-plan.yaml\n    with:\n      environment: sandbox\n\n  test_tf_apply:\n    needs: test_tf_plan\n    uses: ./.github/workflows/tf-apply.yaml\n    with:\n      environment: sandbox\n      tf_pre_run:\n        curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" &amp;&amp; unzip -qq awscliv2.zip &amp;&amp; ./aws/install\n\n  test_tf_feature:\n    uses: ./.github/workflows/tf-feature.yaml\n    with:\n      environment: sandbox\n\n  test_tf_cleanup:\n    needs: test_tf_feature\n    uses: ./.github/workflows/tf-cleanup.yaml\n    with:\n      environment: sandbox\n</code></pre>"}]}